{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as m\n",
    "from pathlib import Path\n",
    "\n",
    "base_directory = \"D:/Descargas/i2ascii-files/i2ascii-files/\"\n",
    "\n",
    "class STATE(Enum):\n",
    "    EVENT_ID = 1\n",
    "    RUN_INFO = 2\n",
    "    WEIGHTS = 3\n",
    "    NEUTRINO = 4\n",
    "    MUON = 5\n",
    "    AAFIT = 6\n",
    "    BBFIT_TRACK = 7\n",
    "    BBFIT_BRIGHT = 8\n",
    "    GRIDFIT = 9\n",
    "    HITS = 10\n",
    "    SELECTED_HITS = 11\n",
    "    \n",
    "def event_id (line, event, state, df_list):\n",
    "    if \"start_event\" in line:\n",
    "        event[\"event_id\"] = line.split()[1]\n",
    "        state = STATE.RUN_INFO\n",
    "      #  print(\"START EVENT: \" + event[\"event_id\"])\n",
    "    return event, state\n",
    "        \n",
    "def run_info (line, event, state, df_list):\n",
    "    element_list = line.split()\n",
    "    if len(element_list) == 7: \n",
    "        event[\"run_id\"] = element_list[0]\n",
    "        event[\"frame_id\"] = element_list[1]\n",
    "        event[\"trigger_counter\"] = element_list[2]\n",
    "        event[\"date\"] = element_list[4]\n",
    "        event[\"time\"] = element_list[5].split(\",\")[0]\n",
    "        state = STATE.WEIGHTS\n",
    "    else:\n",
    "        print(\"ERROR IN STATE: RUN_INFO\")\n",
    "    return event, state\n",
    "\n",
    "def weights (line, event, state, df_list):\n",
    "    element_list = line.split()\n",
    "    if len(element_list) == 4 and element_list[0] == \"weights\": \n",
    "        event[\"w_1\"] = element_list[1]\n",
    "        event[\"w_2\"] = element_list[2]\n",
    "        event[\"w_3\"] = element_list[3]\n",
    "        state = STATE.NEUTRINO\n",
    "    else:\n",
    "        print(\"ERROR IN STATE: WEIGHTS\")\n",
    "    return event, state\n",
    "\n",
    "def cart2sph(x,y,z):\n",
    "    x = float(x)\n",
    "    y = float(y)\n",
    "    z = float(z)\n",
    "    XsqPlusYsq = x**2 + y**2\n",
    "    r = m.sqrt(XsqPlusYsq + z**2)               # r\n",
    "    elev = m.atan2(z,m.sqrt(XsqPlusYsq))     # theta\n",
    "    az = m.atan2(y,x)                           # phi\n",
    "    return elev, az\n",
    "\n",
    "def neutrino (line, event, state, df_list):\n",
    "    element_list = line.split()\n",
    "    if len(element_list) == 9 and element_list[0] == \"nu\": \n",
    "    #    event[\"n_elev\"], event[\"n_az\"] = cart2sph(element_list[1], element_list[2], element_list[3])\n",
    "        # event[\"n_dir_x\"] = element_list[1]\n",
    "        # event[\"n_dir_y\"] = element_list[2]\n",
    "        # event[\"n_dir_z\"] = element_list[3]\n",
    "    #    event[\"n_pos_x\"] = element_list[4]\n",
    "    #    event[\"n_pos_y\"] = element_list[5]\n",
    "    #    event[\"n_pos_z\"] = element_list[6]\n",
    "    #    event[\"n_energy\"] = element_list[7]\n",
    "        state = STATE.MUON\n",
    "    else:\n",
    "        print(\"ERROR IN STATE: NEUTRINO\")\n",
    "    return event, state\n",
    "   \n",
    "def muon (line, event, state, df_list):\n",
    "    element_list = line.split()\n",
    "    if len(element_list) == 9 and element_list[0] == \"muon\": \n",
    "        event[\"m_elev\"], event[\"m_az\"] = cart2sph(element_list[1], element_list[2], element_list[3])\n",
    "        #event[\"m_dir_x\"] = element_list[1]\n",
    "        #event[\"m_dir_y\"] = element_list[2]\n",
    "        #event[\"m_dir_z\"] = element_list[3]\n",
    "        #event[\"m_pos_x\"] = element_list[4]\n",
    "        #event[\"m_pos_y\"] = element_list[5]\n",
    "        #event[\"m_pos_z\"] = element_list[6]\n",
    "        #event[\"m_energy\"] = element_list[7]\n",
    "        state = STATE.AAFIT\n",
    "    else:\n",
    "        print(\"ERROR IN STATE: MUON\")\n",
    "    return event, state\n",
    "\n",
    "def aafit (line, event, state, df_list):\n",
    "    element_list = line.split()\n",
    "    if len(element_list) == 9 and element_list[0] == \"aafit\":\n",
    "        event[\"aafit_elev\"], event[\"aafit_az\"] = cart2sph(element_list[1], element_list[2], element_list[3])\n",
    "        #event[\"aafit_dir_x\"] = element_list[1]\n",
    "        #event[\"aafit_dir_y\"] = element_list[2]\n",
    "        #event[\"aafit_dir_z\"] = element_list[3]\n",
    "        event[\"aafit_lambda\"] = element_list[7]\n",
    "        event[\"aafit_beta\"] = element_list[8]\n",
    "        state = STATE.BBFIT_TRACK\n",
    "    else:\n",
    "        state = STATE.EVENT_ID\n",
    "        print(\"ERROR IN STATE: AAFIT -> Event \" + event[\"event_id\"])\n",
    "    return event, state\n",
    "    \n",
    "def bbfit_track (line, event, state, df_list):\n",
    "    element_list = line.split()\n",
    "    if len(element_list) == 8 and element_list[0] == \"bbfit_track\":\n",
    "        event[\"bbfit_elev\"], event[\"bbfit_az\"] = cart2sph(\n",
    "            0 if element_list[1] == \"nan\" else element_list[1],\n",
    "            0 if element_list[2] == \"nan\" else element_list[2],\n",
    "            0 if element_list[3] == \"nan\" else element_list[3])\n",
    "        # event[\"bbfit_dir_x\"] = np.nan if element_list[1] == \"nan\" else element_list[1]\n",
    "        event[\"bbfit_dir_x\"] = 0 if element_list[1] == \"nan\" else element_list[1]\n",
    "        event[\"bbfit_dir_y\"] = 0 if element_list[2] == \"nan\" else element_list[2]\n",
    "        event[\"bbfit_dir_z\"] = 0 if element_list[3] == \"nan\" else element_list[3]\n",
    "        event[\"bbfit_chi2\"] = element_list[7]\n",
    "        state = STATE.BBFIT_BRIGHT\n",
    "    else:\n",
    "        print(\"ERROR IN STATE: BBFIT_TRACK\")\n",
    "    return event, state\n",
    "\n",
    "def bbfit_bright (line, event, state, df_list):\n",
    "    element_list = line.split()\n",
    "    if len(element_list) == 8 and element_list[0] == \"bbfit_bright\": \n",
    "        state = STATE.GRIDFIT\n",
    "    else:\n",
    "        print(\"ERROR IN STATE: BBFIT_BRIGHT\")\n",
    "    return event, state\n",
    "    \n",
    "def gridfit (line, event, state, df_list):\n",
    "    element_list = line.split()\n",
    "    if len(element_list) == 8 and element_list[0] == \"gridfit\": \n",
    "        state = STATE.HITS\n",
    "    elif element_list[0] == \"hit\":\n",
    "        # Some times there are not gridfit measures...\n",
    "        return hits(line, event, state, df_list)\n",
    "    else:\n",
    "        print(\"ERROR IN STATE: GRIDFIT\")\n",
    "    return event, state\n",
    "\n",
    "def hits (line, event, state, df_list):\n",
    "    element_list = line.split()\n",
    "    if len(element_list) == 14 and element_list[0] == \"hit\":\n",
    "        state = STATE.HITS\n",
    "    elif len(element_list) == 3 and element_list[0] == \"BBFit\": \n",
    "        state = STATE.SELECTED_HITS\n",
    "    else:\n",
    "        print(\"ERROR IN STATE: HITS\")\n",
    "    return event, state\n",
    "   \n",
    "def selected_hits (line, event, state, df_list):\n",
    "    element_list = line.split()\n",
    "    if len(element_list) == 14 and element_list[0] == \"hit\": \n",
    "        state = STATE.SELECTED_HITS\n",
    "    elif \"end_event\" in line:\n",
    "        state = STATE.EVENT_ID\n",
    "        temp_event = event.copy()\n",
    "        df_list.append(temp_event)\n",
    "        event.clear()\n",
    "        event['det_type'] = temp_event['det_type']\n",
    "        #print(\"END EVENT: \" + event[\"event_id\"])\n",
    "    else:\n",
    "        print(\"ERROR IN STATE: SELECTED_HITS\")\n",
    "    return event, state\n",
    "   \n",
    "state_dict = {\n",
    "    STATE.EVENT_ID: event_id,\n",
    "    STATE.RUN_INFO: run_info,\n",
    "    STATE.WEIGHTS: weights,\n",
    "    STATE.NEUTRINO: neutrino,\n",
    "    STATE.MUON: muon,\n",
    "    STATE.AAFIT: aafit,\n",
    "    STATE.BBFIT_TRACK: bbfit_track,\n",
    "    STATE.BBFIT_BRIGHT: bbfit_bright,\n",
    "    STATE.GRIDFIT: gridfit,\n",
    "    STATE.HITS: hits,\n",
    "    STATE.SELECTED_HITS: selected_hits\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FILE: D:\\Descargas\\i2ascii-files\\i2ascii-files\\MC_025800_anumu_CC_a_reco.i3.gz.txt\n",
      "\n",
      "FILE: D:\\Descargas\\i2ascii-files\\i2ascii-files\\MC_025800_numu_CC_a_reco.i3.gz.txt\n",
      "     aafit_az        aafit_beta  aafit_elev    aafit_lambda  bbfit_az  \\\n",
      "0   -2.345721    0.130539349905    1.136707  -5.86985595954  0.000000   \n",
      "1    1.572092   0.0836670029347    1.037053   -5.7793266451  0.000000   \n",
      "2    0.491548   0.0202099344442    0.387720  -5.75199073111  0.000000   \n",
      "3    1.300769  0.00798271375863    1.384257  -6.10337920021  0.000000   \n",
      "4    2.791342  0.00972042559206    0.827787  -5.10942573606  2.794801   \n",
      "5    1.456237   0.0209666765195    0.776675  -5.54507124415  1.582917   \n",
      "6    2.814358  0.00818518948302    0.839293   -6.3655854932  0.000000   \n",
      "7   -0.894596   0.0106758698475    0.991760  -5.30778362015  0.000000   \n",
      "8    2.260261    0.011746644012    0.896976  -5.52212398141  2.225389   \n",
      "9   -0.782032   0.0415682655896    0.516033  -5.40763571919  0.000000   \n",
      "10  -2.183115    0.116968604817    1.082496  -4.95486163107  0.000000   \n",
      "11   1.815705    0.024691221056    1.103998  -5.37431636339  0.000000   \n",
      "12  -0.243206   0.0317539006601    0.931055  -5.31149290723  0.000000   \n",
      "13   2.046671   0.0287449029604    1.121187  -5.92340634307  0.000000   \n",
      "14  -0.710608   0.0486663475673    0.765411  -6.58411025799 -0.381602   \n",
      "15  -1.904332   0.0697171457401    1.429972  -5.13927956011  0.000000   \n",
      "16   0.740518   0.0427641549729    1.175631  -6.18598085176  0.000000   \n",
      "17  -0.476245   0.0136301950118    0.651254  -5.29057018921 -0.499170   \n",
      "18   0.362981   0.0194551907554    0.719513  -5.78575025317  0.272021   \n",
      "19  -0.056280  0.00924119023623    0.977525  -5.12386142161 -0.062498   \n",
      "20  -2.931053   0.0412754716326    1.175978  -5.13041098074  0.000000   \n",
      "21   0.048233  0.00703470368156    1.217145  -5.86537209078  0.000000   \n",
      "22  -0.970303  0.00636730888866    1.255863  -4.75640754174 -0.504589   \n",
      "23   2.222527   0.0886473299872    1.211580   -5.2957899493  0.000000   \n",
      "24  -0.457535  0.00927052538822    0.628621  -5.65664009478 -0.524840   \n",
      "25  -0.536025   0.0163089993526    1.020083  -5.70166302701  0.000000   \n",
      "26   3.100758    0.010819594248    1.057152  -5.97136140345  0.000000   \n",
      "27   2.423708      0.0137951185    0.217475  -5.61833790169  2.471685   \n",
      "28   1.645060   0.0230981284875    1.083441  -5.20119714527  1.249636   \n",
      "29  -0.245229  0.00977172071355    0.265926  -5.84856146928 -0.500935   \n",
      "..        ...               ...         ...             ...       ...   \n",
      "449  0.639561               0.0   -0.237475  -5.35453157577  0.341610   \n",
      "450 -1.626485  0.00790031236958    1.233886  -5.70606731999 -2.343555   \n",
      "451  1.396282  0.00744658741003    1.113619   -5.0173178589  1.042002   \n",
      "452 -2.058317   0.0118010087122   -0.078108  -5.40494991926 -2.061668   \n",
      "453  2.477375  0.00796001693553    1.023643  -4.91835050186  2.507164   \n",
      "454 -2.069984  0.00473314670127   -1.071029  -5.60475723064 -2.149586   \n",
      "455 -3.070161    0.012509045061    0.411784   -5.4122738034  0.000000   \n",
      "456 -1.442918   0.0129955760048    0.892502  -5.35354698926 -0.610113   \n",
      "457  2.137938   0.0321250854752   -1.142882  -6.34154291635  1.458011   \n",
      "458  2.668998    0.026969798268   -0.724187  -5.97140763293  1.905294   \n",
      "459 -2.348366   0.0181527295326   -1.075221  -5.73094692632  0.000000   \n",
      "460  3.131564    0.009515340619    0.075798  -4.67998254938 -3.020423   \n",
      "461  2.576760  0.00306531116638    1.181752  -4.40919930517  2.576957   \n",
      "462  2.406025  0.00757376925032    0.685242  -4.29681776071  2.476349   \n",
      "463  1.866128  0.00745852044253    0.879550  -5.70841344017  2.141070   \n",
      "464 -1.150287  0.00442645045393    0.888889  -4.17822463332 -1.136871   \n",
      "465 -0.142266  0.00800391018852    1.226236  -5.64281134112  0.417303   \n",
      "466  1.792518   0.0204860766368    0.434184  -4.94778804315  0.844859   \n",
      "467 -2.405014  0.00790358680664    0.949030  -4.60498913971  1.849209   \n",
      "468 -0.609801   0.0132082913215   -0.367430    -5.998620801 -0.815216   \n",
      "469 -1.631878   0.0107091022563    0.682868  -6.10453464335 -0.434285   \n",
      "470 -0.194136  0.00838660230333    0.586368  -4.95502914933 -0.229656   \n",
      "471  1.025259    0.429109774982    0.914524  -6.68142923327  2.438882   \n",
      "472 -2.221007    0.026379933566    1.076029   -5.8259424688 -1.737414   \n",
      "473 -0.288256   0.0169354317711    0.374020  -6.53940420344 -0.182225   \n",
      "474  2.159466   0.0256068800531    0.619772  -6.51707335084  0.000000   \n",
      "475 -0.790448   0.0130802583368    0.856956  -5.89343114802  0.000000   \n",
      "476  2.034709  0.00778719025513   -1.040016  -5.95294012236  2.450935   \n",
      "477  0.237314  0.00580911746088   -1.356772  -6.09266901369  0.000000   \n",
      "478  1.991913  0.00800835784681   -0.701312  -6.18122077128  0.000000   \n",
      "\n",
      "         bbfit_chi2        bbfit_dir_x       bbfit_dir_y       bbfit_dir_z  \\\n",
      "0    0.943145803497                  0                 0    0.953328222068   \n",
      "1    0.843270905799                  0                 0    0.911433941414   \n",
      "2    0.494768582033                  0                 0    0.949644215148   \n",
      "3    0.881043837967                  0                 0    0.990165609105   \n",
      "4    0.933981750743    -0.625166763663     0.22593311098    0.747074793427   \n",
      "5     1.36983345043  -0.00848345346586    0.699884448152    0.714205705839   \n",
      "6     1.14360076952                  0                 0    0.792190039106   \n",
      "7     3.12237663937                  0                 0    0.968305512917   \n",
      "8     1.05337775762    -0.375523462342    0.489296496256    0.787128368172   \n",
      "9     1.04044004943                  0                 0    0.924484727368   \n",
      "10   0.571589078557                  0                 0     0.92972301327   \n",
      "11    1.02316411177                  0                 0    0.882648002214   \n",
      "12    1.63177281205                  0                 0    0.715969755987   \n",
      "13    7.39556413288                  0                 0    0.983995288902   \n",
      "14    2.02704612428     0.657790076101   -0.263952172621    0.705437074693   \n",
      "15   0.631828605563                  0                 0    0.990310287813   \n",
      "16   0.484166982148                  0                 0    0.989373236909   \n",
      "17     0.7814680061     0.698965622976   -0.381093735378    0.605156692728   \n",
      "18    1.22830414299     0.740761202862    0.206624722328    0.639201896475   \n",
      "19    1.04352553858     0.554151046277  -0.0346786542902    0.831693458461   \n",
      "20   0.314673468419                  0                 0    0.996605144605   \n",
      "21   0.811509473927                  0                 0    0.947727127121   \n",
      "22    0.59116127526     0.273616734997     -0.1511118001    0.949894260536   \n",
      "23   0.736310001069                  0                 0    0.961755389192   \n",
      "24    1.13855623879     0.716172038051   -0.414668056454    0.561380454657   \n",
      "25    2.35819656247                  0                 0     0.87776085742   \n",
      "26    1.32648046075                  0                 0    0.897875949688   \n",
      "27    1.87269298412    -0.766153129779    0.606873395643    0.211457001282   \n",
      "28   0.867258466173     0.151677186978    0.455928918382    0.876996495052   \n",
      "29    4.48589226987     0.792256227736   -0.433773703097    0.429150840749   \n",
      "..              ...                ...               ...               ...   \n",
      "449   3.73626542829     0.932063005289    0.331394746882   -0.146410641386   \n",
      "450   4.49785848915    -0.694566830468   -0.712349886527    0.100670537783   \n",
      "451   1.92775367131     0.223893661487    0.383183927068    0.896125943371   \n",
      "452    2.2897153785    -0.469244437274   -0.877898216769  -0.0954168700063   \n",
      "453  0.736685661249     -0.41265070524    0.303677500196    0.858777835845   \n",
      "454   2.64499333996    -0.292353996394   -0.447407363728   -0.845195712054   \n",
      "455   1.47306063335                  0                 0    0.334974902857   \n",
      "456   3.59990920492     0.711071901622   -0.497100958985    0.497259879038   \n",
      "457   4.25053729952     0.111059837484    0.980523235516    -0.16198733627   \n",
      "458   10.9934454374    -0.328233607406     0.94439817323   0.0193594774855   \n",
      "459   2.32344452128                  0                 0   0.0568669420411   \n",
      "460   1.70092084422    -0.988760436645   -0.120397146751   0.0886415589908   \n",
      "461   1.75594257118    -0.326381799756    0.206738857862    0.922352408485   \n",
      "462   1.12134303351    -0.612333583292    0.480400608031    0.627903526488   \n",
      "463   1.11463494761    -0.344111168736    0.536538532422     0.77052832964   \n",
      "464  0.734619228007     0.261835500674   -0.565055708968    0.782402847867   \n",
      "465  0.928948695595     0.363349775813    0.161088132618    0.917620593681   \n",
      "466   7.76176381087     0.633976665203    0.714237215374   -0.296544748988   \n",
      "467   8.85151170279   -0.0845499682532    0.295797931588    0.951501385462   \n",
      "468    2.1566811214     0.636573845048   -0.675714786802   -0.371730099263   \n",
      "469   60.6551892927     0.893855353929   -0.414585518617   -0.170708681696   \n",
      "470   1.62304113571     0.833226496352   -0.194792260546    0.517483894443   \n",
      "471    16.620664268   -0.0034127218148  0.00289034485451    0.999989999568   \n",
      "472   5.54332473935    -0.117992722527   -0.701598349574    0.702735706582   \n",
      "473   3.58699060977     0.908793660061   -0.167463063396    0.382165155176   \n",
      "474   2.67419685706                  0                 0     0.38384207409   \n",
      "475    1.0063837912                  0                 0    0.797398730685   \n",
      "476   3.68688170074    -0.478156944488    0.395169414967   -0.784351368911   \n",
      "477   8.24235921293                  0                 0   -0.905855651847   \n",
      "478   2.87204747388                  0                 0    0.625986155873   \n",
      "\n",
      "     bbfit_elev  ... event_id  frame_id      m_az    m_elev  run_id  \\\n",
      "0      1.570796  ...        1     73557 -1.787980  1.230895   25800   \n",
      "1      1.570796  ...        2     66099  1.702232  1.005222   25800   \n",
      "2      1.570796  ...        3     95343 -3.026856  1.256481   25800   \n",
      "3      1.570796  ...        4    160419  1.447459  1.274115   25800   \n",
      "4      0.843651  ...        5      8919  2.819365  0.832965   25800   \n",
      "5      0.795489  ...        6     81967  1.372126  0.845083   25800   \n",
      "6      1.570796  ...        7     81971 -1.587605  0.896058   25800   \n",
      "7      1.570796  ...        8      3601 -0.151505  0.954182   25800   \n",
      "8      0.906139  ...        9    123817  1.899561  0.991368   25800   \n",
      "9      1.570796  ...       10    130509  2.218007  1.002746   25800   \n",
      "10     1.570796  ...       11     33967 -2.973575  1.151746   25800   \n",
      "11     1.570796  ...       12     54323  2.718913  1.159403   25800   \n",
      "12     1.570796  ...       13     54377 -0.511560  0.919260   25800   \n",
      "13     1.570796  ...       14     39357  0.728474  1.220604   25800   \n",
      "14     0.783040  ...       15     31947 -0.386265  0.763149   25800   \n",
      "15     1.570796  ...       16    114285 -2.167546  1.437538   25800   \n",
      "16     1.570796  ...       17    126669  0.597826  1.447010   25800   \n",
      "17     0.649963  ...       18     22995 -0.449445  0.656321   25800   \n",
      "18     0.693460  ...       19    136171  0.129850  0.712078   25800   \n",
      "19     0.982151  ...       20     88669 -0.073609  0.985847   25800   \n",
      "20     1.570796  ...       21    151549 -1.581933  1.424176   25800   \n",
      "21     1.570796  ...       22    151551  0.604930  1.204764   25800   \n",
      "22     1.252897  ...       23     98109 -0.551811  1.261533   25800   \n",
      "23     1.570796  ...       24    113655  3.076111  1.035322   25800   \n",
      "24     0.596053  ...       25    112619 -0.767968  0.615688   25800   \n",
      "25     1.570796  ...       26     46049 -2.465254  1.053160   25800   \n",
      "26     1.570796  ...       27     75661  3.091667  1.060756   25800   \n",
      "27     0.213065  ...       28    131063  2.423507  0.220327   25800   \n",
      "28     1.069575  ...       29    131077  1.258754  1.072756   25800   \n",
      "29     0.443552  ...       30    149557 -0.267870  0.263863   25800   \n",
      "..          ...  ...      ...       ...       ...       ...     ...   \n",
      "449   -0.146939  ...      194    103355  0.311201 -0.254409   25800   \n",
      "450    0.100841  ...      195    103395 -0.957560 -0.153861   25800   \n",
      "451    1.110962  ...      196    103501  1.413072  1.088780   25800   \n",
      "452   -0.095562  ...      197    144445 -2.013591 -0.119720   25800   \n",
      "453    1.032879  ...      198    144479  2.459329  1.020252   25800   \n",
      "454   -1.006931  ...      199    144517 -2.061959 -1.063535   25800   \n",
      "455    1.570796  ...      200    144541 -3.095646  0.412472   25800   \n",
      "456    0.520438  ...      201    144555 -1.434418  0.886724   25800   \n",
      "457   -0.162704  ...      202    144569  1.221895 -0.473869   25800   \n",
      "458    0.019361  ...      203    144609 -2.991196 -0.991792   25800   \n",
      "459    1.570796  ...      204     72965 -2.011573 -1.384435   25800   \n",
      "460    0.088758  ...      205     72971  3.114723  0.095432   25800   \n",
      "461    1.174126  ...      206     73007  2.578738  1.180204   25800   \n",
      "462    0.678857  ...      207     73031  2.406979  0.686720   25800   \n",
      "463    0.879670  ...      208     73061  2.141582  0.875296   25800   \n",
      "464    0.898515  ...      209     73075 -1.145515  0.889691   25800   \n",
      "465    1.162052  ...      210     73095  0.468925  1.235780   25800   \n",
      "466   -0.301073  ...      211     73101  1.727448  0.575588   25800   \n",
      "467    1.258080  ...      212    104587 -2.433983  0.951312   25800   \n",
      "468   -0.380872  ...      213    104589 -0.870383 -0.379470   25800   \n",
      "469   -0.171549  ...      214    104605 -1.070476 -0.725768   25800   \n",
      "470    0.543908  ...      215    104641 -0.195368  0.591670   25800   \n",
      "471    1.566324  ...      216    104651  2.762066  1.097650   25800   \n",
      "472    0.779235  ...      217    104663 -1.494388  0.573979   25800   \n",
      "473    0.392138  ...      218    104709 -0.335450 -0.826612   25800   \n",
      "474    1.570796  ...      219    104711 -1.900918 -0.849265   25800   \n",
      "475    1.570796  ...      220    104717  0.832938  0.929897   25800   \n",
      "476   -0.901650  ...      221    104743  2.109372 -0.963427   25800   \n",
      "477   -1.570796  ...      222    155279  0.811325 -1.352497   25800   \n",
      "478    1.570796  ...      223    155319  2.894929 -0.688607   25800   \n",
      "\n",
      "             time trigger_counter            w_1         w_2        w_3  \n",
      "0    18:56:23.000               0     91530000.0   3191000.0  1000000.0  \n",
      "1    19:56:06.000               2   1979000000.0   2555000.0  1000000.0  \n",
      "2    20:51:02.000               3   1193000000.0   2466000.0  1000000.0  \n",
      "3    20:18:49.000               4   1650000000.0   2340000.0  1000000.0  \n",
      "4    18:30:24.000               5   2379000000.0   2759000.0  1000000.0  \n",
      "5    18:12:13.000               6   1714000000.0   2740000.0  1000000.0  \n",
      "6    18:01:05.000               7   1946000000.0   2783000.0  1000000.0  \n",
      "7    21:00:51.000               8   1954000000.0   2581000.0  1000000.0  \n",
      "8    19:15:05.000              10   1229000000.0   2638000.0  1000000.0  \n",
      "9    20:11:03.000              11   1093000000.0   2657000.0  1000000.0  \n",
      "10   19:59:49.000              12   1792000000.0   2449000.0  1000000.0  \n",
      "11   19:13:40.000              13   1525000000.0   2424000.0  1000000.0  \n",
      "12   18:38:17.000              14   1633000000.0   2786000.0  1000000.0  \n",
      "13   21:51:52.000              15    333400000.0   2797000.0  1000000.0  \n",
      "14   20:00:32.000              16   1792000000.0   2856000.0  1000000.0  \n",
      "15   22:30:38.000              17   2367000000.0   2115000.0  1000000.0  \n",
      "16   18:14:55.000              18   1186000000.0   2263000.0  1000000.0  \n",
      "17   20:54:13.000              19   2126000000.0   2959000.0  1000000.0  \n",
      "18   19:51:28.000              20   1325000000.0   2952000.0  1000000.0  \n",
      "19   19:07:11.000              21   9312000000.0   2285000.0  1000000.0  \n",
      "20   18:17:03.000              22   2743000000.0   2106000.0  1000000.0  \n",
      "21   17:51:26.000              23  10650000000.0   2086000.0  1000000.0  \n",
      "22   21:37:00.000              24  15270000000.0   1953000.0  1000000.0  \n",
      "23   17:43:54.000              25   7495000000.0   2258000.0  1000000.0  \n",
      "24   21:48:49.000              26   6468000000.0   2841000.0  1000000.0  \n",
      "25   18:19:03.000              27   4517000000.0   2253000.0  1000000.0  \n",
      "26   18:18:05.000              28   3035000000.0   2348000.0  1000000.0  \n",
      "27   21:45:27.000              29   8961000000.0   3869000.0  1000000.0  \n",
      "28   20:54:46.000              30   4642000000.0   2278000.0  1000000.0  \n",
      "29   18:47:31.000              31  11270000000.0   3753000.0  1000000.0  \n",
      "..            ...             ...            ...         ...        ...  \n",
      "449  20:56:59.000             200      1.497e+16   6875000.0  1000000.0  \n",
      "450  20:10:16.000             201      1.242e+16   8997000.0  1000000.0  \n",
      "451  22:30:39.000             202      1.313e+16   2116000.0  1000000.0  \n",
      "452  22:41:15.000             203       3.17e+15  12670000.0  1000000.0  \n",
      "453  19:14:26.000             204      3.591e+15   3457000.0  1000000.0  \n",
      "454  19:20:44.000             205       1.77e+15   1298000.0  1000000.0  \n",
      "455  20:36:03.000             206      9.565e+15   5930000.0  1000000.0  \n",
      "456  21:08:57.000             207      3.781e+15   4059000.0  1000000.0  \n",
      "457  20:18:44.000             208      3.316e+15   5416000.0  1000000.0  \n",
      "458  17:43:31.000             209      4.554e+16    311700.0  1000000.0  \n",
      "459  19:56:41.000             210      2.291e+16    213200.0  1000000.0  \n",
      "460  20:12:46.000             211      6.716e+16   6520000.0  1000000.0  \n",
      "461  18:47:52.000             212      2.714e+16   1358000.0  1000000.0  \n",
      "462  19:06:32.000             213      8.623e+16   1933000.0  1000000.0  \n",
      "463  19:28:23.000             214      3.746e+16   2019000.0  1000000.0  \n",
      "464  18:07:28.000             215      9.232e+16   1370000.0  1000000.0  \n",
      "465  19:47:44.000             216      1.847e+16   1452000.0  1000000.0  \n",
      "466  18:36:43.000             217      5.387e+16   2818000.0  1000000.0  \n",
      "467  20:48:41.000             218      2.171e+16   2231000.0  1000000.0  \n",
      "468  21:17:52.000             219      1.825e+16   3669000.0  1000000.0  \n",
      "469  18:51:20.000             220       7.51e+16    462700.0  1000000.0  \n",
      "470  17:51:45.000             221      1.828e+17   1610000.0  1000000.0  \n",
      "471  19:12:35.000             222      7.106e+16   1020000.0  1000000.0  \n",
      "472  20:58:44.000             223       2.69e+16   3529000.0  1000000.0  \n",
      "473  21:14:22.000             224       4.16e+16    483700.0  1000000.0  \n",
      "474  19:52:20.000             225      3.767e+16    481800.0  1000000.0  \n",
      "475  21:32:02.000             226      7.538e+16   1419000.0  1000000.0  \n",
      "476  20:52:24.000             227      1.543e+16    574200.0  1000000.0  \n",
      "477  19:52:38.000             228      1.419e+16    282400.0  1000000.0  \n",
      "478  19:57:21.000             230      6.551e+16    549400.0  1000000.0  \n",
      "\n",
      "[479 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "pathlist = Path(base_directory).glob('*.txt')\n",
    "counter = 0;\n",
    "df_list = []\n",
    "for path in pathlist:\n",
    "    # because path is object not string\n",
    "    path_in_str = str(path)\n",
    "    print(\"\\nFILE: \" + path_in_str)\n",
    "    detection_type = 1 if \"anumu\" in path_in_str else 2\n",
    "    with open(path_in_str, \"r\") as f_test:\n",
    "        line = f_test.readline()\n",
    "        current_state = STATE.EVENT_ID\n",
    "        current_event = {}\n",
    "        current_event['det_type'] = detection_type\n",
    "        while line:\n",
    "            current_event, current_state = state_dict[current_state](line, current_event, current_state, df_list)\n",
    "            line = f_test.readline()\n",
    "            \n",
    "    counter += 1\n",
    "    if counter > 1:\n",
    "        break;\n",
    "    \n",
    "df = pd.DataFrame(df_list)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(479, 22)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Métricas de evaluación que se utilizarán. No nos preocupamos en negarlas debido a que no se utilizarán de forma automática,\n",
    "# solo las visualizaremos\n",
    "metrics_dict = {\n",
    "  'MAE': metrics.mean_absolute_error,\n",
    "  'RMSE': lambda y, y_pred:\n",
    "          sqrt(metrics.mean_squared_error(y, y_pred)),\n",
    "  'MAPE': lambda y, y_pred:\n",
    "          np.mean(np.abs((y - y_pred) / y)) * 100,\n",
    "  'E_VARIANCE': metrics.explained_variance_score\n",
    "}\n",
    "\n",
    "algorithms_dict = {}\n",
    "\n",
    "# Algoritmo 1: Estandarización + OLS\n",
    "steps = [('standardization', StandardScaler()),\n",
    "         ('ols', LinearRegression())]\n",
    "algorithms_dict['STD_OLS'] = Pipeline(steps)\n",
    "\n",
    "# Algoritmo 2: Estandarización + KNN\n",
    "steps = [('standardization', StandardScaler()),\n",
    "         ('knn', KNeighborsRegressor(n_neighbors=10))]\n",
    "algorithms_dict['STD_KNN'] = Pipeline(steps)\n",
    "\n",
    "# Algoritmo 3: Estandarización + RandomForest\n",
    "steps = [('standardization', StandardScaler()),\n",
    "         ('rforest', RandomForestRegressor())]\n",
    "algorithms_dict['STD_RF'] = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[['m_elev','m_az']]\n",
    "data2 = df.drop(['m_elev', 'm_az'], axis=1)\n",
    "data = data2.drop(['event_id', 'run_id', 'date', 'time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.tail of        aafit_az        aafit_beta  aafit_elev    aafit_lambda  bbfit_az  \\\n",
       "0     -2.345721    0.130539349905    1.136707  -5.86985595954  0.000000   \n",
       "1      1.572092   0.0836670029347    1.037053   -5.7793266451  0.000000   \n",
       "2      0.491548   0.0202099344442    0.387720  -5.75199073111  0.000000   \n",
       "3      1.300769  0.00798271375863    1.384257  -6.10337920021  0.000000   \n",
       "4      2.791342  0.00972042559206    0.827787  -5.10942573606  2.794801   \n",
       "5      1.456237   0.0209666765195    0.776675  -5.54507124415  1.582917   \n",
       "6      2.814358  0.00818518948302    0.839293   -6.3655854932  0.000000   \n",
       "7     -0.894596   0.0106758698475    0.991760  -5.30778362015  0.000000   \n",
       "8      2.260261    0.011746644012    0.896976  -5.52212398141  2.225389   \n",
       "9     -0.782032   0.0415682655896    0.516033  -5.40763571919  0.000000   \n",
       "10    -2.183115    0.116968604817    1.082496  -4.95486163107  0.000000   \n",
       "11     1.815705    0.024691221056    1.103998  -5.37431636339  0.000000   \n",
       "12    -0.243206   0.0317539006601    0.931055  -5.31149290723  0.000000   \n",
       "13     2.046671   0.0287449029604    1.121187  -5.92340634307  0.000000   \n",
       "14    -0.710608   0.0486663475673    0.765411  -6.58411025799 -0.381602   \n",
       "15    -1.904332   0.0697171457401    1.429972  -5.13927956011  0.000000   \n",
       "16     0.740518   0.0427641549729    1.175631  -6.18598085176  0.000000   \n",
       "17    -0.476245   0.0136301950118    0.651254  -5.29057018921 -0.499170   \n",
       "18     0.362981   0.0194551907554    0.719513  -5.78575025317  0.272021   \n",
       "19    -0.056280  0.00924119023623    0.977525  -5.12386142161 -0.062498   \n",
       "20    -2.931053   0.0412754716326    1.175978  -5.13041098074  0.000000   \n",
       "21     0.048233  0.00703470368156    1.217145  -5.86537209078  0.000000   \n",
       "22    -0.970303  0.00636730888866    1.255863  -4.75640754174 -0.504589   \n",
       "23     2.222527   0.0886473299872    1.211580   -5.2957899493  0.000000   \n",
       "24    -0.457535  0.00927052538822    0.628621  -5.65664009478 -0.524840   \n",
       "25    -0.536025   0.0163089993526    1.020083  -5.70166302701  0.000000   \n",
       "26     3.100758    0.010819594248    1.057152  -5.97136140345  0.000000   \n",
       "27     2.423708      0.0137951185    0.217475  -5.61833790169  2.471685   \n",
       "28     1.645060   0.0230981284875    1.083441  -5.20119714527  1.249636   \n",
       "29    -0.245229  0.00977172071355    0.265926  -5.84856146928 -0.500935   \n",
       "...         ...               ...         ...             ...       ...   \n",
       "22538  1.767703    0.183886446865    0.514484  -5.68200247058  0.000000   \n",
       "22539  2.880245  0.00902849756744    0.303236  -5.26941230253  3.029093   \n",
       "22540 -1.034983  0.00704740189019    0.666715  -4.48194640595  0.000000   \n",
       "22541  1.354583   0.0176011365528    0.222712  -5.56158626716  0.000000   \n",
       "22542 -1.443747   0.0379360696123   -0.116124  -6.06826849622 -2.775207   \n",
       "22543 -1.512142   0.0626618133313   -0.075745  -5.58243758735  0.000000   \n",
       "22544  1.681899   0.0183068247592    0.124049  -5.84388270356  1.744106   \n",
       "22545 -2.595059   0.0220042512067    0.709352  -5.59605746901 -3.018865   \n",
       "22546 -1.863530  0.00923732210458   -0.570583  -5.39225519076 -1.780123   \n",
       "22547 -1.366609   0.0248815777065   -0.832421  -5.90087792571  0.000000   \n",
       "22548  1.235628    0.064803450667   -0.495698  -5.85940500137  1.159542   \n",
       "22549  1.480077  0.00958406646099    1.056521  -5.77333384485  2.423671   \n",
       "22550  2.719503  0.00813259822817   -1.390976  -6.03349567984  2.592944   \n",
       "22551 -2.658390    0.039046680629    0.224418  -5.85880762662 -2.758461   \n",
       "22552  2.479449   0.0121522186026    0.295827  -5.67287499702  2.445043   \n",
       "22553  1.375873   0.0751176656284    0.433159    -6.141378991  1.312872   \n",
       "22554 -1.079689   0.0225994313626    0.270106  -5.49954696295  0.000000   \n",
       "22555 -2.497246   0.0194074768291    0.242302  -5.82637100517 -2.562680   \n",
       "22556 -2.605627   0.0751379757592    0.681030  -7.66917504508  0.000000   \n",
       "22557 -1.193751   0.0173008360222    0.349682  -5.58832146867  0.000000   \n",
       "22558  1.281606     0.01993646338   -0.154914   -6.3269387542  2.492839   \n",
       "22559  2.178725   0.0537149866649    0.403656  -5.77981018839  2.295208   \n",
       "22560 -2.327778    0.017062041252   -0.007362  -5.33072302646 -1.789291   \n",
       "22561 -3.124245  0.00728814845056    0.113458  -5.53182499711  1.168800   \n",
       "22562  1.555617   0.0142672010143   -0.471249  -6.15363004541  1.005379   \n",
       "22563 -1.435495   0.0900256941592    0.250358  -5.43888282581  0.000000   \n",
       "22564  0.217941   0.0243654886942    0.167844  -6.18495001037  0.000000   \n",
       "22565  0.032135   0.0529111738871    0.419392   -5.7852601023  2.608606   \n",
       "22566 -1.840740   0.0105826331429   -1.013830  -5.57666690221 -1.871026   \n",
       "22567 -2.079815   0.0143209169406   -0.769035  -5.03740175559 -2.001554   \n",
       "\n",
       "           bbfit_chi2        bbfit_dir_x       bbfit_dir_y      bbfit_dir_z  \\\n",
       "0      0.943145803497                  0                 0   0.953328222068   \n",
       "1      0.843270905799                  0                 0   0.911433941414   \n",
       "2      0.494768582033                  0                 0   0.949644215148   \n",
       "3      0.881043837967                  0                 0   0.990165609105   \n",
       "4      0.933981750743    -0.625166763663     0.22593311098   0.747074793427   \n",
       "5       1.36983345043  -0.00848345346586    0.699884448152   0.714205705839   \n",
       "6       1.14360076952                  0                 0   0.792190039106   \n",
       "7       3.12237663937                  0                 0   0.968305512917   \n",
       "8       1.05337775762    -0.375523462342    0.489296496256   0.787128368172   \n",
       "9       1.04044004943                  0                 0   0.924484727368   \n",
       "10     0.571589078557                  0                 0    0.92972301327   \n",
       "11      1.02316411177                  0                 0   0.882648002214   \n",
       "12      1.63177281205                  0                 0   0.715969755987   \n",
       "13      7.39556413288                  0                 0   0.983995288902   \n",
       "14      2.02704612428     0.657790076101   -0.263952172621   0.705437074693   \n",
       "15     0.631828605563                  0                 0   0.990310287813   \n",
       "16     0.484166982148                  0                 0   0.989373236909   \n",
       "17       0.7814680061     0.698965622976   -0.381093735378   0.605156692728   \n",
       "18      1.22830414299     0.740761202862    0.206624722328   0.639201896475   \n",
       "19      1.04352553858     0.554151046277  -0.0346786542902   0.831693458461   \n",
       "20     0.314673468419                  0                 0   0.996605144605   \n",
       "21     0.811509473927                  0                 0   0.947727127121   \n",
       "22      0.59116127526     0.273616734997     -0.1511118001   0.949894260536   \n",
       "23     0.736310001069                  0                 0   0.961755389192   \n",
       "24      1.13855623879     0.716172038051   -0.414668056454   0.561380454657   \n",
       "25      2.35819656247                  0                 0    0.87776085742   \n",
       "26      1.32648046075                  0                 0   0.897875949688   \n",
       "27      1.87269298412    -0.766153129779    0.606873395643   0.211457001282   \n",
       "28     0.867258466173     0.151677186978    0.455928918382   0.876996495052   \n",
       "29      4.48589226987     0.792256227736   -0.433773703097   0.429150840749   \n",
       "...               ...                ...               ...              ...   \n",
       "22538   1.42218960611                  0                 0   0.925944521278   \n",
       "22539   2.11467470683    -0.948357554079    0.107142154307   0.298560728148   \n",
       "22540   3.91935910402                  0                 0    0.30506450217   \n",
       "22541   3.44826599811                  0                 0   0.600011901684   \n",
       "22542   7.19220307943    -0.932383252446   -0.357765532296  0.0516264898876   \n",
       "22543   2.68892537263                  0                 0  0.0669880460181   \n",
       "22544   2.38325962121    -0.171464768056    0.979429566445   0.106384010497   \n",
       "22545   1.39810154351    -0.766089907077   -0.094495686163    0.63574902247   \n",
       "22546   3.49939961224    -0.172275486438   -0.810943219846  -0.559188922421   \n",
       "22547   4.56384319529                  0                 0  -0.344647850304   \n",
       "22548   11.0457316534     0.399513857497    0.916056279996  0.0350652185073   \n",
       "22549   1.97490511457    -0.733633616128    0.640753914929  -0.226309826987   \n",
       "22550   11.6691808464    -0.630143170723    0.385173544819  -0.674211335386   \n",
       "22551   2.42735848512    -0.905133976476   -0.364813194736   0.218274637956   \n",
       "22552   7.25021107897    -0.709800101012    0.593681763827   0.379111830338   \n",
       "22553   2.56880799656     0.232514990122    0.881404431103   0.411172723074   \n",
       "22554   2.71189117971                  0                 0  0.0544069922797   \n",
       "22555    1.7586487537    -0.807378551459   -0.527715240143   0.263925178725   \n",
       "22556   1.69719116952                  0                 0   0.426072247824   \n",
       "22557   3.48440089578                  0                 0   0.573409045083   \n",
       "22558   7.22417664563    -0.585473679054    0.443929081027  -0.678341759111   \n",
       "22559   3.22752164097    -0.648126308187    0.732425645187   0.208530484362   \n",
       "22560   2.79124609207   -0.0934771548926   -0.420993229396    0.90223429458   \n",
       "22561   6.92924032206   0.00175001693537  0.00411624681913   0.999989996926   \n",
       "22562   15.5358323456     0.437997234941    0.690279465214  -0.575910307329   \n",
       "22563   2.39744200726                  0                 0   0.297902010831   \n",
       "22564   7.40242023298                  0                 0  -0.361685898576   \n",
       "22565   2.51127559417    -0.838639624258    0.494743661478   0.227842687073   \n",
       "22566   2.22198832314    -0.159847618449   -0.516323405405  -0.841343496978   \n",
       "22567   1.45501832213    -0.299242643875   -0.651181617458  -0.697435546249   \n",
       "\n",
       "       bbfit_elev  det_type frame_id trigger_counter            w_1  \\\n",
       "0        1.570796         1    73557               0     91530000.0   \n",
       "1        1.570796         1    66099               2   1979000000.0   \n",
       "2        1.570796         1    95343               3   1193000000.0   \n",
       "3        1.570796         1   160419               4   1650000000.0   \n",
       "4        0.843651         1     8919               5   2379000000.0   \n",
       "5        0.795489         1    81967               6   1714000000.0   \n",
       "6        1.570796         1    81971               7   1946000000.0   \n",
       "7        1.570796         1     3601               8   1954000000.0   \n",
       "8        0.906139         1   123817              10   1229000000.0   \n",
       "9        1.570796         1   130509              11   1093000000.0   \n",
       "10       1.570796         1    33967              12   1792000000.0   \n",
       "11       1.570796         1    54323              13   1525000000.0   \n",
       "12       1.570796         1    54377              14   1633000000.0   \n",
       "13       1.570796         1    39357              15    333400000.0   \n",
       "14       0.783040         1    31947              16   1792000000.0   \n",
       "15       1.570796         1   114285              17   2367000000.0   \n",
       "16       1.570796         1   126669              18   1186000000.0   \n",
       "17       0.649963         1    22995              19   2126000000.0   \n",
       "18       0.693460         1   136171              20   1325000000.0   \n",
       "19       0.982151         1    88669              21   9312000000.0   \n",
       "20       1.570796         1   151549              22   2743000000.0   \n",
       "21       1.570796         1   151551              23  10650000000.0   \n",
       "22       1.252897         1    98109              24  15270000000.0   \n",
       "23       1.570796         1   113655              25   7495000000.0   \n",
       "24       0.596053         1   112619              26   6468000000.0   \n",
       "25       1.570796         1    46049              27   4517000000.0   \n",
       "26       1.570796         1    75661              28   3035000000.0   \n",
       "27       0.213065         1   131063              29   8961000000.0   \n",
       "28       1.069575         1   131077              30   4642000000.0   \n",
       "29       0.443552         1   149557              31  11270000000.0   \n",
       "...           ...       ...      ...             ...            ...   \n",
       "22538    1.570796         1   101887             274      2.211e+15   \n",
       "22539    0.303184         1   101891             275      4.721e+15   \n",
       "22540    1.570796         1   101904             276      7.495e+15   \n",
       "22541    1.570796         1    75392             277      2.781e+15   \n",
       "22542    0.051649         1    87313             278      1.903e+16   \n",
       "22543    1.570796         1    87339             279      3.878e+16   \n",
       "22544    0.106586         1    87354             280      7.661e+16   \n",
       "22545    0.688979         1    87365             281      3.869e+16   \n",
       "22546   -0.593407         1    87373             282       1.94e+16   \n",
       "22547   -1.570796         1    87375             283      1.991e+16   \n",
       "22548    0.035072         1    87392             284      1.666e+16   \n",
       "22549   -0.228288         1    87403             285      9.351e+16   \n",
       "22550   -0.739896         1    38478             286      2.836e+16   \n",
       "22551    0.220046         1    38479             287      5.118e+16   \n",
       "22552    0.388836         1    38490             288      1.526e+17   \n",
       "22553    0.423740         1    38493             289       3.52e+16   \n",
       "22554    1.570796         1    38501             290      3.255e+16   \n",
       "22555    0.267089         1    38507             291      8.666e+16   \n",
       "22556    1.570796         1    38510             292      4.938e+16   \n",
       "22557    1.570796         1    38513             293      5.327e+16   \n",
       "22558   -0.745503         1    38528             294      7.972e+15   \n",
       "22559    0.210072         1    38551             295        7.5e+15   \n",
       "22560    1.124923         1    38559             296      1.178e+17   \n",
       "22561    1.566323         1    38560             297      3.877e+16   \n",
       "22562   -0.613717         1    38575             298      1.285e+16   \n",
       "22563    1.570796         1     2985             299      5.883e+16   \n",
       "22564   -1.570796         1     3004             300      1.263e+16   \n",
       "22565    0.229862         1     3043             301      2.346e+16   \n",
       "22566   -0.999764         1     3051             302      2.594e+16   \n",
       "22567   -0.771813         1     3060             303      3.542e+16   \n",
       "\n",
       "             w_2        w_3  \n",
       "0      3191000.0  1000000.0  \n",
       "1      2555000.0  1000000.0  \n",
       "2      2466000.0  1000000.0  \n",
       "3      2340000.0  1000000.0  \n",
       "4      2759000.0  1000000.0  \n",
       "5      2740000.0  1000000.0  \n",
       "6      2783000.0  1000000.0  \n",
       "7      2581000.0  1000000.0  \n",
       "8      2638000.0  1000000.0  \n",
       "9      2657000.0  1000000.0  \n",
       "10     2449000.0  1000000.0  \n",
       "11     2424000.0  1000000.0  \n",
       "12     2786000.0  1000000.0  \n",
       "13     2797000.0  1000000.0  \n",
       "14     2856000.0  1000000.0  \n",
       "15     2115000.0  1000000.0  \n",
       "16     2263000.0  1000000.0  \n",
       "17     2959000.0  1000000.0  \n",
       "18     2952000.0  1000000.0  \n",
       "19     2285000.0  1000000.0  \n",
       "20     2106000.0  1000000.0  \n",
       "21     2086000.0  1000000.0  \n",
       "22     1953000.0  1000000.0  \n",
       "23     2258000.0  1000000.0  \n",
       "24     2841000.0  1000000.0  \n",
       "25     2253000.0  1000000.0  \n",
       "26     2348000.0  1000000.0  \n",
       "27     3869000.0  1000000.0  \n",
       "28     2278000.0  1000000.0  \n",
       "29     3753000.0  1000000.0  \n",
       "...          ...        ...  \n",
       "22538   848900.0  1000000.0  \n",
       "22539  2016000.0  1000000.0  \n",
       "22540  1066000.0  1000000.0  \n",
       "22541  2571000.0  1000000.0  \n",
       "22542  2191000.0  1000000.0  \n",
       "22543    92440.0  1000000.0  \n",
       "22544  1889000.0  1000000.0  \n",
       "22545   628400.0  1000000.0  \n",
       "22546   371300.0  1000000.0  \n",
       "22547    77360.0  1000000.0  \n",
       "22548   149100.0  1000000.0  \n",
       "22549   301600.0  1000000.0  \n",
       "22550    51580.0  1000000.0  \n",
       "22551  1357000.0  1000000.0  \n",
       "22552   803000.0  1000000.0  \n",
       "22553   905800.0  1000000.0  \n",
       "22554  1515000.0  1000000.0  \n",
       "22555  1162000.0  1000000.0  \n",
       "22556  2083000.0  1000000.0  \n",
       "22557  1196000.0  1000000.0  \n",
       "22558   121100.0  1000000.0  \n",
       "22559   354700.0  1000000.0  \n",
       "22560  1694000.0  1000000.0  \n",
       "22561  1937000.0  1000000.0  \n",
       "22562   169600.0  1000000.0  \n",
       "22563  1404000.0  1000000.0  \n",
       "22564  1002000.0  1000000.0  \n",
       "22565  1265000.0  1000000.0  \n",
       "22566    95850.0  1000000.0  \n",
       "22567   141100.0  1000000.0  \n",
       "\n",
       "[22568 rows x 16 columns]>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-e9f597bed4d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0malg_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0malgorithms_dict_3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     y_pred_dict[alg_name] = cross_val_predict(alg, data, target, \n\u001b[1;32m----> 5\u001b[1;33m                                                               cv=KFold(n_splits=10, random_state=1))\n\u001b[0m",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[1;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[0;32m    775\u001b[0m     prediction_blocks = parallel(delayed(_fit_and_predict)(\n\u001b[0;32m    776\u001b[0m         clone(estimator), X, y, train, test, verbose, fit_params, method)\n\u001b[1;32m--> 777\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    778\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m     \u001b[1;31m# Concatenate the predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 920\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    921\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_predict\u001b[1;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[0;32m    850\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    851\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 852\u001b[1;33m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    853\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'decision_function'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'predict_proba'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'predict_log_proba'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m         \u001b[0mn_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m                 \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'_final_estimator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\regression.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    453\u001b[0m                 delayed_query(\n\u001b[0;32m    454\u001b[0m                     self._tree, X[s], n_neighbors, return_distance)\n\u001b[1;32m--> 455\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    456\u001b[0m             )\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    915\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36m_tree_query_parallel_helper\u001b[1;34m(tree, data, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[0munder\u001b[0m \u001b[0mPyPy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \"\"\"\n\u001b[1;32m--> 292\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Se realizan las 6 predicciones y se almacenan en un diccionario con nombres descriptivos \n",
    "y_pred_dict = {}\n",
    "for alg_name, alg in algorithms_dict_3.items():\n",
    "    y_pred_dict[alg_name] = cross_val_predict(alg, data, target, \n",
    "                                                              cv=KFold(n_splits=10, random_state=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En lugar de importar la función del script utilizado en clase, se reimplementa con ligeras variaciones para\n",
    "# adaptarse a las necesidades del ejercicio\n",
    "def grafica_real_vs_pred_mod(y_true, y_pred, evaluated_metrics, algorithm_name):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(y_true, y_pred, edgecolors=(0, 0, 0))\n",
    "    ax.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'k--', lw=4)\n",
    "    ax.set_xlabel('Real class value')\n",
    "    ax.set_ylabel('Prediction')\n",
    "    title = algorithm_name + '\\n'\n",
    "    for name, result in evaluated_metrics.items():\n",
    "        title += name + ': ' + str(round(result, 3)) + ' '\n",
    "        \n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_comp = target.join(pd.DataFrame(y_pred_dict['STD_RF']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST 1\n",
    "# Se evaluan las predicciones y se representan al estilo visto en clase\n",
    "evaluated = {}\n",
    "for name, prediction in y_pred_dict.items():\n",
    "    for metric_name, metric in metrics_dict.items():\n",
    "        evaluated[metric_name] = metric(target, prediction)\n",
    "\n",
    "    grafica_real_vs_pred_mod(target, prediction, evaluated, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
