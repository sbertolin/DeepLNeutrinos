{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from structured.DataRetriever import DataRetriever\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dt = DataRetriever(\"D:/Descargas/i2ascii-files/i2ascii-files/\", 300)\n",
    "dt.set_target(['m_elev','m_az'])\n",
    "dt.get_det_type(False)\n",
    "dt.set_selected_hits(5, True)\n",
    "target, data, compare_data = dt.load_data(\n",
    "    get_sel_events = True,\n",
    "    filter_bbfit_null = False,\n",
    "    get_bbfit_data = False,\n",
    "    get_aafit_data = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En lugar de importar la función del script utilizado en clase, se reimplementa con ligeras variaciones para\n",
    "# adaptarse a las necesidades del ejercicio\n",
    "def grafica_real_vs_pred_mod(y_true, y_pred, evaluated_metrics, algorithm_name):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(y_true, y_pred, edgecolors=(0, 0, 0))\n",
    "    ax.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'k--', lw=4)\n",
    "    ax.set_xlabel('Real class value')\n",
    "    ax.set_ylabel('Prediction')\n",
    "    title = algorithm_name + '\\n'\n",
    "    for name, result in evaluated_metrics.items():\n",
    "        title += name + ': ' + str(round(result, 3)) + ' '\n",
    "        \n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import cross_val_predict, cross_validate\n",
    "from sklearn.svm import LinearSVR, SVR, NuSVR\n",
    "#import crfsuite as sk_crf\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "#import xgboost as xgb\n",
    "\n",
    "rand_state = 50\n",
    "jobs = 6\n",
    "\n",
    "# Métricas de evaluación que se utilizarán. No nos preocupamos en negarlas debido a que no se utilizarán de forma automática,\n",
    "# solo las visualizaremos\n",
    "metrics_dict = {\n",
    "  'MAE': metrics.mean_absolute_error,\n",
    "  'RMSE': lambda y, y_pred:\n",
    "          sqrt(metrics.mean_squared_error(y, y_pred)),\n",
    "  'E_VARIANCE': metrics.explained_variance_score\n",
    "}\n",
    "\n",
    "algorithms_dict = {}\n",
    "\n",
    "# Algoritmo 1: No Outliers + Standarización + RandomForest\n",
    "#steps = [\n",
    "#    ('standardization', StandardScaler()),\n",
    "#    ('rforest', RandomForestRegressor(n_estimators=50, random_state=rand_state, n_jobs=jobs))]\n",
    "#algorithms_dict['STD_RF'] = Pipeline(steps)\n",
    "\n",
    "# Algoritmo 2: No Outliers + Standarización + Multi-RandomForest\n",
    "steps = [\n",
    "    ('standardization', StandardScaler()),\n",
    "    ('multi_rforest', MultiOutputRegressor(RandomForestRegressor(\n",
    "        n_estimators=200, max_features=0.5, min_samples_leaf=5, random_state=rand_state, \n",
    "        min_samples_split=2, criterion='mse', n_jobs=jobs), n_jobs=jobs))]\n",
    "algorithms_dict['STD_MULT_RF'] = Pipeline(steps)\n",
    "\n",
    "# Algoritmo 3: No Outliers + Standarización + MLPRegressor\n",
    "steps = [\n",
    "    ('standardization', StandardScaler()),\n",
    "    ('mlp', MLPRegressor(random_state=rand_state, hidden_layer_sizes=(100,), activation='tanh',\n",
    "                        solver='adam', alpha=0.001, learning_rate='adaptive', shuffle=False,\n",
    "                        early_stopping=True, beta_1=0.8))]\n",
    "algorithms_dict['STD_MLP'] = Pipeline(steps)\n",
    "\n",
    "# Algoritmo 4: No Outliers + Standarización + Multi-GradientBoostingRegressor\n",
    "steps = [\n",
    "    ('standardization', StandardScaler()),\n",
    "    ('multi_gbr', MultiOutputRegressor(GradientBoostingRegressor(random_state=rand_state), n_jobs=jobs))]\n",
    "algorithms_dict['STD_MULT_GBR'] = Pipeline(steps)\n",
    "\n",
    "\n",
    "algorithms_dict2 = {}\n",
    "\n",
    "# Algoritmo 5: No Outliers + Standarización + LinearSVR\n",
    "#steps = [\n",
    "#    ('standardization', StandardScaler()),\n",
    "#    ('linsvr', LinearSVR(random_state=rand_state))]\n",
    "#algorithms_dict2['STD_LSVR'] = Pipeline(steps)\n",
    "\n",
    "# Algoritmo 6: No Outliers + Standarización + Multi-LinearSVR\n",
    "#steps = [\n",
    "#    ('standardization', StandardScaler()),\n",
    "#    ('multi_linsvr', MultiOutputRegressor(LinearSVR(random_state=rand_state), n_jobs=jobs))]\n",
    "#algorithms_dict2['STD_MULT_LSVR'] = Pipeline(steps)\n",
    "\n",
    "# Algoritmo 7: No Outliers + Standarización + SVR\n",
    "#steps = [\n",
    "#    ('standardization', StandardScaler()),\n",
    "#    ('svr', SVR())]\n",
    "#algorithms_dict2['STD_SVR'] = Pipeline(steps)\n",
    "\n",
    "# Algoritmo 8: No Outliers + Standarización + Multi-SVR\n",
    "#steps = [\n",
    "#    ('standardization', StandardScaler()),\n",
    "#    ('multi_linsvr', MultiOutputRegressor(SVR(), n_jobs=jobs))]\n",
    "#algorithms_dict2['STD_MULT_SVR'] = Pipeline(steps)\n",
    "\n",
    "# Algoritmo 9: No Outliers + Standarización + NuSVR\n",
    "#steps = [\n",
    "#    ('standardization', StandardScaler()),\n",
    "#    ('svr', NuSVR())]\n",
    "#algorithms_dict2['STD_SVR'] = Pipeline(steps)\n",
    "\n",
    "# Algoritmo 10: No Outliers + Standarización + Multi-NuSVR\n",
    "steps = [\n",
    "    ('standardization', StandardScaler()),\n",
    "    ('multi_linsvr', MultiOutputRegressor(NuSVR(nu=0.9, verbose=True), n_jobs=jobs))]\n",
    "algorithms_dict2['STD_MULT_NuSVR'] = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('BBFIT MAE: ' + str(metrics_dict['MAE'](compare_data, target)))\n",
    "print('BBFIT RMSE: ' + str(metrics_dict['RMSE'](compare_data, target)))\n",
    "print('BBFIT E_VARIANCE: ' + str(metrics_dict['E_VARIANCE'](compare_data, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se realizan las 6 predicciones y se almacenan en un diccionario con nombres descriptivos \n",
    "y_pred_dict = {}\n",
    "for alg_name, alg in algorithms_dict.items():\n",
    "    y_pred_dict[alg_name] = cross_val_predict(alg, data, target, n_jobs=jobs,\n",
    "                                                              cv=KFold(n_splits=5, random_state=rand_state))\n",
    "\n",
    "evaluated = {}\n",
    "for name, prediction in y_pred_dict.items():\n",
    "    for metric_name, metric in metrics_dict.items():\n",
    "        evaluated[metric_name] = metric(target, prediction)\n",
    "\n",
    "    grafica_real_vs_pred_mod(target, prediction, evaluated, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se realizan las 6 predicciones y se almacenan en un diccionario con nombres descriptivos \n",
    "y_pred_dict2 = {}\n",
    "for alg_name, alg in algorithms_dict2.items():\n",
    "    y_pred_dict2[alg_name] = cross_val_predict(alg, data, target, n_jobs=jobs,\n",
    "                                                              cv=KFold(n_splits=5, random_state=rand_state))\n",
    "\n",
    "evaluated2 = {}\n",
    "for name, prediction in y_pred_dict2.items():\n",
    "    for metric_name, metric in metrics_dict.items():\n",
    "        evaluated2[metric_name] = metric(target, prediction)\n",
    "\n",
    "    grafica_real_vs_pred_mod(target, prediction, evaluated2, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_estimators': [50, 100, 150],\n",
    "              'max_depth': [4, 6, 8, None],\n",
    "              'min_samples_split': [2, 3, 4],\n",
    "              'min_samples_leaf': [5],\n",
    "              'max_features': [0.35, 0.4, 0.45],\n",
    "              'criterion': ['mse', 'mae']\n",
    "             # 'warm_leaf_nodes': [True, False]\n",
    "             }\n",
    "\n",
    "modelo_optimizador = MultiOutputRegressor(RandomForestRegressor(random_state=rand_state, n_jobs=jobs), n_jobs=jobs)\n",
    "modelo_optimizador = RandomForestRegressor(random_state=rand_state, n_jobs=jobs)\n",
    "\n",
    "#gs_cv = GridSearchCV(modelo_optimizador, param_grid, n_jobs=jobs, cv=5).fit(X_train,y_train)\n",
    "\n",
    "print(gs_cv.best_params_)\n",
    "n_estimators = gs_cv.best_params_['n_estimators']\n",
    "#max_depth = gs_cv.best_params_['max_depth']\n",
    "min_samples_split = gs_cv.best_params_['min_samples_split']\n",
    "min_samples_leaf = gs_cv.best_params_['min_samples_leaf']\n",
    "max_features = gs_cv.best_params_['max_features']\n",
    "#warm_leaf_nodes = gs_cv.best_params_['warm_leaf_nodes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "from sklearn.svm import LinearSVR, SVR, NuSVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "param_grid = {'nu': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "              'C': [1.0],\n",
    "              'kernel': ['rbf'],\n",
    "              'gamma': ['scale'],\n",
    "              'coef0': [0.0]\n",
    "              #'tol': []\n",
    "             }\n",
    "\n",
    "#X_tunning_train, X_tunning_test, y_tunning_train, y_tunning_test = train_test_split(X_train, y_train, test_size=0.3, random_state=rand_state)\n",
    "\n",
    "X_train_std = StandardScaler().fit_transform(X_train)\n",
    "X_test_std = StandardScaler().fit_transform(X_test)\n",
    "\n",
    "all_params = sorted(param_grid)\n",
    "combinations = it.product(*(param_grid[Name] for Name in all_params))\n",
    "\n",
    "for l_comb in combinations:\n",
    "    it_dict = dict(zip(all_params,l_comb))\n",
    "    print(it_dict)\n",
    "    \n",
    "    if it_dict['kernel'] == 'rbf' and it_dict['coef0'] > 0.0:\n",
    "        continue\n",
    "    \n",
    "    print(X_train_std.shape)\n",
    "    m_test = MultiOutputRegressor(NuSVR(**it_dict), n_jobs=jobs)\n",
    "    m_test.fit(X_train_std, y_train)\n",
    "    predicted = m_test.predict(X_test_std)\n",
    "        \n",
    "    print('NuSVR MAE: ' + str(metrics_dict['MAE'](y_test, predicted)))\n",
    "    print('NuSVR RMSE: ' + str(metrics_dict['RMSE'](y_test, predicted)))\n",
    "    print('NuSVR E_VARIANCE: ' + str(metrics_dict['E_VARIANCE'](y_test, predicted)))\n",
    "    print('\\n\\n')\n",
    "    \n",
    "    del m_test\n",
    "    del predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'hidden_layer_sizes': [(20,50), (30,20), (100,10)],\n",
    "              'activation': ['tanh'],\n",
    "              'solver': ['adam'],\n",
    "              'alpha': [0.001],\n",
    "              'learning_rate': ['adaptive'],\n",
    "              'shuffle': [False],\n",
    "              'random_state': [rand_state],\n",
    "              'early_stopping': [True],\n",
    "              'beta_1': [0.8],\n",
    "              'beta_2': [0.99],\n",
    "              'verbose': [True]\n",
    "             }\n",
    "\n",
    "X_train_std = StandardScaler().fit_transform(X_train)\n",
    "#X_test_std = StandardScaler().fit_transform(X_test)\n",
    "\n",
    "modelo_optimizador = MLPRegressor(random_state=rand_state, verbose=True)\n",
    "\n",
    "gs_cv = GridSearchCV(modelo_optimizador, param_grid, n_jobs=jobs, cv=5).fit(X_train_std, y_train)\n",
    "\n",
    "print(gs_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
